"""A set of helper functions."""

import csv

import ast
import pathlib

from uppaal_c_language.backend.parsers.generated.uppaal_c_language_parser import UppaalCLanguageParser
from uppaal_c_language.backend.parsers.uppaal_c_language_semantics import UppaalCLanguageSemantics
from uppaal_model.backend.parsers.uppaal_xml_model_parser import uppaal_xml_to_system, uppaal_system_to_xml
from uppyyl_observation_matcher.backend.logger.logger import matcher_log
from uppyyl_observation_matcher.backend.trace.parser import trace_xml_to_dict, trace_dict_to_trace
from uppyyl_observation_matcher.backend.interface.verifyta import VerifyTAInterface


def parse_config_value(string):
    """Parses a configuration value.

    Args:
        string: The configuration value as raw string.

    Returns:
        The parsed configuration value.
    """
    try:
        res = ast.literal_eval(string)
        return res
    except (ValueError, SyntaxError):
        pass

    try:
        res = pathlib.Path(string)
        return res
    except NotImplementedError:
        pass

    raise ValueError(f'Value "{string}" has an unsupported type.')


def parse_obs_csv_value(string):
    """Parses a value from an observation CSV file.

    Args:
        string: The value as raw string.

    Returns:
        The parsed value.
    """
    if not string:
        return "NOB"

    try:
        res = ast.literal_eval(string)
        return res
    except (ValueError, SyntaxError):
        pass

    if string == "true":
        return True
    elif string == "false":
        return False

    return string


def print_atomic_val(val):
    """Prints an atomic value (bool, int, or other value) to a string.

    Args:
        val: The atomic value.

    Returns:
        The string representation of the value.
    """
    if isinstance(val, bool):
        return "true" if val else "false"
    elif isinstance(val, int):
        return str(val)
    else:
        return "NOB"


def load_model_from_file(model_path):
    """Loads a model at a given path.

    Args:
        model_path: The model path.
    """
    matcher_log.debug(f'Loading model: {model_path}')
    with open(model_path) as file:
        system_xml_str = file.read()
    model = uppaal_xml_to_system(system_xml_str)
    return model


def save_model_to_file(model, model_path):
    """Saves a model to a given path.

    Args:
        model: The given model.
        model_path: The model path.
    """
    matcher_log.debug(f'Saving model: {model_path}')
    model_xml_str = uppaal_system_to_xml(model)
    with open(model_path, "w") as file:
        file.write(model_xml_str)


def load_trace_from_file(trace_file_path, system):
    """Loads a trace generated by verifyta from a file.

    Args:
        trace_file_path: The trace file path.
        system: The system for which the trace was generated.

    Returns:
        The loaded trace.
    """
    with open(trace_file_path, 'r') as file:
        trace_xml_str = file.read()
    trace_dict = trace_xml_to_dict(trace_xml_str=trace_xml_str)
    trace = trace_dict_to_trace(trace_dict=trace_dict, system=system)
    return trace


def get_instance_data(model, config):
    """Extract the instance data of a model from a dummy query to verifyta.

    Args:
        model: The model for which instance data should be extracted.
        config: The configuration file containing path information.

    Returns:
        The extracted instance data.
    """
    verifyta = VerifyTAInterface(verifyta_path=config["verifyta_path"], do_print=False)
    uppaal_c_parser = UppaalCLanguageParser(semantics=UppaalCLanguageSemantics())

    # Adapt the model to explicitly contain all required data
    adapted_model = model.copy()
    for tmpl_id, tmpl in adapted_model.templates.items():
        local_decl_ext_str = f'bool __TMPL_{tmpl.name} = -1;'
        local_decl_ext_ast = uppaal_c_parser.parse(local_decl_ext_str, rule_name="UppaalDeclaration")
        tmpl.declaration.ast["decls"].extend(local_decl_ext_ast["decls"])
        tmpl.declaration.update_text()

    adapted_model.queries = []
    adapted_model.new_query(query_text=f'E<> true', query_comment="The details query.")

    save_model_to_file(model=adapted_model, model_path=config["details_model_file_path"])

    # Generate dummy trace (containing the instance information)
    trace_file_path = config["details_model_trace_file_path"]
    trace_file_path_base = trace_file_path.parent.joinpath(str(trace_file_path.stem)[:-1])
    settings = ['-t', '0', '-X', str(trace_file_path_base)]  # '-x', verifyta_modified_model_file_path

    _output, _is_timeout = verifyta.execute_verifyta(
        model_file_path=config["details_model_file_path"],
        output_dir_path=config["output_dir_path"], settings=settings)
    with open(trace_file_path, 'r') as file:
        trace_xml_str = file.read()
    trace_dict = trace_xml_to_dict(trace_xml_str=trace_xml_str)

    # Gather instance data (including all implicit and explicit arguments during instantiation)
    system_decl_ast = model.system_declaration.ast
    instance_asts = list(filter(lambda decl: decl["astType"] == "Instantiation", system_decl_ast["decls"]))
    instance_asts_dict = dict([(inst["instanceName"], inst) for inst in instance_asts])
    instance_data = {}
    for proc_id, proc_data in trace_dict["system"]["processes"].items():
        tmpl_var = [v["name"] for v in proc_data["variables"].values() if v["name"].startswith("__TMPL_")][0]
        tmpl_name = tmpl_var.split("__TMPL_")[1]
        implicit_args_asts = [{"astType": 'Integer', "val": val} for val in proc_data["implicit_args"]]
        if proc_id in instance_asts_dict:
            args = instance_asts_dict[proc_id]["args"] + implicit_args_asts
        else:
            args = implicit_args_asts

        instance_data[proc_id] = {
            "template_name": tmpl_name,
            "args": args
        }

    return instance_data


def dbm_union(dbm, other):
    """Calculates the union of two DBMs.
    Be careful, as the result is not necessarily a zone anymore.

    Args:
        dbm: The first DBM (and target of the result).
        other: The other DBM.

    Returns:
        The union DBM.
    """
    for i in range(len(dbm.matrix)):
        for j in range(len(dbm.matrix[0])):
            dbm.matrix[i][j] = max(other.matrix[i][j], dbm.matrix[i][j])
    dbm.canonicalize()
    return dbm


def load_observation_data_from_csv(csv_data_file_path, instance_data):
    """Loads observation data from a CSV file.

    Args:
        csv_data_file_path: The CSV file path.
        instance_data: The template and argument data of all instances.

    Returns:
        The loaded observation data.
    """
    instance_names = list(instance_data.keys())
    observation_data = []
    with open(csv_data_file_path, 'r') as file:
        data = list(csv.reader(file, delimiter=',', quotechar='|'))
        header = data[0]
        for d in data[1:]:
            parsed_values = list(map(parse_obs_csv_value, d))
            data_point_raw = dict(zip(header, parsed_values))
            data_point = {"t": None, "vars": {}, "locs": {}}
            for var_name, val in data_point_raw.items():
                if var_name == "t":
                    data_point["t"] = val
                elif var_name in instance_names:
                    data_point["locs"][var_name] = {"name": val}
                else:
                    data_point["vars"][var_name] = val
            observation_data.append(data_point)

    return observation_data
